{
  "name": "Disaster detection via twitter",
  "tagline": "Predictive classification model for determining if a Tweet is discussing a disaster event (i.e., building collapse, wildfire, terrorist attack)",
  "body": "###1. Project summary\r\n---\r\n**Goal:** Create a predictive model to classify a tweet as pertaining to a disaster event or not, *solely* based on the tweet text.\r\n\r\n**Data:** 10,876 classified tweet entries in the \"Disasters on Social Media\" data set from CrowdFlower at http://www.crowdflower.com/data-for-everyone. These were compiled by searching for tweets with disaster related keywords (i.e., hijacking, hurricane, and explosion) and then they were classified.\r\n\r\n**Machine learning tools** \r\n\r\n1. **Natural Language Toolkit (NLTK)** - For initial preprocessing and tokenization of tweets using the nltk.tokenize package.\r\n\r\n2. **GENSIM** - For seamless transformation from a high dimensional \"bag of words\" (BOW) feature space to a lower dimensional \"topic\" space (each topic expresses discovered relations amongst the words in the Tweet data set using Latent Semantic Indexing or LSI).\r\n\r\n3. **Scikit-Learn** - For trivial implementation the final Logistic Regression model which predicts \"disaster\" or \"not disaster\" based on each Tweets \"topic\" representation.\r\n\r\n###2. Clean and tokenize all the tweets\r\n---\r\n1. Convert hyphens and apostrophes from utf8 to ascii\r\n2. Remove all remaining utf8 characters\r\n3. Clean any HTML tags using HTMLParser module\r\n4. Break on hyphens\r\n5. Employ NLTK for initial tweet tokenization\r\n  * Keep handles (username) and hashtags and reduce length (e.g., looooooovvvvveeee to looovvveee)\r\n    * In general, the english language has at most three identical letters in a row\r\n6. Introduce special tokens\r\n  * **|-num-|** for numbers (detect comma separation as in 1,000,000)\r\n  * **|-num_alpha-|** for mixed numerical and alphabetical (maybe useful for interstates, planes, trains, ...) \r\n    * Make sure not to convert handles! These are typically mixed numeric and alphabetic\r\n  * **|-num_units-|** for zero, one, ..., ten\r\n  * **|-num_tens-|** for ten, twenty, ..., ninety\r\n  * **|-num_scales-|** for hundred, thousand, ..., billion\r\n  * **|-website-|** for any hyperlinks\r\n8. Simplify common face emoticons down to just eyes and mouth (nose does not really convey emotion) and normalize (eyes first mouth second)\r\n  * Most common eyes : ; = 8\r\n  * Most common mouths ( ) [ ] d p { } / @ |\r\n9. Stem words using NLTK Porter stemmer (e.g., fires becomes fire)\r\n\r\n**NOTE:** stop words (i.e., high frequency words like \"and\") are not removed. Keeping them helps improve the final model performance--perhaps by allowing for better word-word relations to be encoded in the discovered \"topics\".\r\n\r\n\r\n\r\n\r\n\r\n###6. Decide on a model dimensionality and check accuracy\r\n\r\n---\r\n\r\n**Model used**: logistic regression (see: https://en.wikipedia.org/wiki/Logistic_regression).\r\n\r\n**Why**: logistic regression is one of the simplest models (linear in the features), making it particularly well suited to high dimensional problems. As dimensionality increases linear separability of the classes improves. Additionally, such highly constrained models suffer little from the so called \"curse of dimensionality\" which plagues weakly constrained models such as k-nearest neighbors (see https://en.wikipedia.org/wiki/Curse_of_dimensionality for details on this phenomenon).\r\n\r\n**Two tests across a range of dimensions**:\r\n\r\n1. k-fold cross validation error to assess how well the model will generalize to new tweets.\r\n  * Unfortunately this does not account well for testing generalizability to tweets with new (non-dictionary) tokens. Ideally, the word2vec mapping will remedy the relatively small dictionary.\r\n2. Training error to fit the whole dataset.\r\n\r\n![cross validation](https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/cv_and_roc_data/cross_validation.png)\r\n\r\n\r\n\r\n###8. Check out the \"topics\"\r\n---\r\n  1. Print out the top 10 topics with the top ten tokens they are composed of\r\n  2. Plot some topics against each other with colors to indicate class\r\n\r\n`Topic 0: 0.426*\"?\" + 0.234*\"#\" + 0.205*\"@\" + 0.196*\"|-no_w2v-|\" + 0.188*\"'\" + 0.185*\".\" + 0.183*\"the\" + 0.160*\"|-num-|\" + 0.158*\"i\" + 0.156*\"a\"`\r\n\r\n`Topic 1: -0.808*\"?\" + 0.160*\"|-num-|\" + 0.159*\"'\" + 0.148*\":\" + 0.127*\"#\" + 0.110*\"of\" + 0.107*\"in\" + 0.096*\"|-website-|\" + 0.093*\"famili\" + 0.093*\"...\"`\r\n\r\n###...\r\n\r\n`Topic 9: -0.242*\"kill\" + 0.231*\"#\" + 0.222*\"!\" + 0.212*\"|-num_alpha-|\" + -0.208*\"obama\" + -0.203*\"declar\" + -0.203*\"disast\" + -0.173*\"|-num_units-|\" + 0.167*\"bomb\" + -0.150*\"for\"`\r\n\r\n`Topic 10: -0.463*\"!\" + -0.321*\"obama\" + -0.312*\"declar\" + -0.287*\"disast\" + -0.208*\"for\" + -0.200*\"@\" + -0.185*\"saipan\" + -0.184*\"typhoon\" + 0.180*\".\" + -0.166*\"devast\"`\r\n\r\n![Topics](https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/cv_and_roc_data/topics.png)\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}