{
  "name": "Disaster detection via twitter",
  "tagline": "Predictive classification model for determining if a Tweet is discussing a disaster event (i.e., building collapse, wildfire, terrorist attack)",
  "body": "---\r\n###1. Project summary\r\n---\r\n**Goal:** Create a predictive model to classify a tweet as pertaining to a disaster event or not, *solely* based on the tweet text.\r\n\r\n**Data:** 10,876 classified tweet entries in the \"Disasters on Social Media\" data set from CrowdFlower at http://www.crowdflower.com/data-for-everyone. These were compiled by searching for tweets with disaster related keywords (i.e., hijacking, hurricane, and explosion) and then they were classified.\r\n\r\n**Machine learning tools** \r\n\r\n1. **Natural Language Toolkit (NLTK)** - For initial preprocessing and tokenization of tweets using the nltk.tokenize package.\r\n\r\n2. **GENSIM** - For transforming the high dimensional \"bag of words\" (BOW) feature space to a lower dimensional \"topic\" space via Latent Semantic Indexing or LSI.\r\n\r\n3. **Scikit-Learn** - Fitting of final Logistic Regression classification model to tweets in \"topic\" form.\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n###2. Tweet preparation\r\n---\r\n1. Convert hyphens and apostrophes from utf8 to ascii\r\n2. Remove all remaining utf8 characters\r\n3. Clean any HTML tags using HTMLParser module\r\n4. Break on hyphens\r\n5. Employ NLTK for initial tweet tokenization\r\n  * Keep handles (username) and hashtags and reduce length (e.g., looooooovvvvveeee to looovvveee)\r\n  * @ and # are separated from text\r\n6. Introduce special tokens\r\n  * **|-num-|** for numbers (detect comma separation as in 1,000,000)\r\n  * **|-num_alpha-|** for mixed numerical and alphabetical (interstates, planes, trains) but not handles \r\n  * **|-num_units-|** for zero, one, ..., ten\r\n  * **|-num_tens-|** for ten, twenty, ..., ninety\r\n  * **|-num_scales-|** for hundred, thousand, ..., billion\r\n  * **|-website-|** for any hyperlinks\r\n8. Simplify common face emoticons down to just eyes and mouth (nose does not really convey emotion) and normalize (eyes first mouth second)\r\n  * Most common eyes : ; = 8\r\n  * Most common mouths ( ) [ ] d p { } / @ |\r\n9. Stem words using NLTK Porter stemmer (e.g., fires becomes fire)\r\n\r\n**NOTE:** stop words (like \"and\") are not removed as keeping them improves performance--perhaps by allowing for better word-word relations to be encoded in the discovered \"topics\".\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n\r\n###3. Mapping uncommon words\r\n---\r\n**Low frequency words**: occur *once* in the whole cleaned and tokenized tweet data set (also for unknown words).\r\n\r\n**High frequency words**: occur greater than *once* in the whole cleaned and tokenized tweet data set.\r\n\r\nLeverage word2vec and pre-trained Google News vectors to quantify the similarity between two words. Low frequency *stemmed* tokens are replaced by most similar high frequency *stemmed* token (see cartoon).\r\n\r\n![mapping_visual2](https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/images/mapping_procedure.png)\r\n\r\nEmploy special **|-no_w2v-|** token for word2vec unrecognized words.\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n\r\n###4. Tweet topic generation\r\n---\r\n\r\n**Some useful definitions:**\r\n\r\n1. **Bag of words (BOW)**:  vectors like [1,0,0,2,4,0,...,0] where each count specifies how many time a certain token appears in a tweet (sparse, i.e., mostly full of 0's).\r\n2. **Term frequency–inverse document frequency (TFIDF)**: rescaled BOW vectors where each word count is penalized (shrunk) in accord with how many of the documents contains the word (measure of uniqueness).\r\n3. **Latent semantic indexing (LSI)**: constructs *user specified* number of \"topics\" (linear combinations of the old TFIDF dimensions). These are constructed so so as to describe as much variance in the data as possible. \r\n\r\n**Dictionary**: tokens from *all* the tweets for get maximal word recognition. Tokens that appear only once are excluded.\r\n\r\n**Corpus**: only tweets of 100% confidence in classification to maximize reliability (some tweets with <100% appeared incorrectly labeled upon personal inspection).\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n\r\n###5. Accuracy and number of topics\r\n---\r\n\r\n**Model used**: logistic regression (well suited to high dimensional problems).\r\n\r\n![cross validation](https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/cv_and_roc_data/cross_validation.png)\r\n\r\n**Conclusion**: Overall, D=250 seems good. I use this dimensionality from here onward.\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n###6. Model class separability\r\n---\r\n\r\n**Receiver operating characteristic (ROC) curve:**\r\n\r\n![ROC analysis](https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/cv_and_roc_data/roc.png)\r\n\r\n**NOTE**: May want to tune threshold towards more false disaster predictions (better safe than sorry).\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n###7. Explore the topics\r\n---\r\n\r\n**Top 10 topics with the top ten tokens**\r\n\r\n\r\n`Topic 0: 0.426*\"?\" + 0.234*\"#\" + 0.205*\"@\" + 0.196*\"|-no_w2v-|\" + 0.188*\"'\" + 0.185*\".\" + 0.183*\"the\" + 0.160*\"|-num-|\" + 0.158*\"i\" + 0.156*\"a\"`\r\n\r\n`Topic 1: -0.808*\"?\" + 0.160*\"|-num-|\" + 0.159*\"'\" + 0.148*\":\" + 0.127*\"#\" + 0.110*\"of\" + 0.107*\"in\" + 0.096*\"|-website-|\" + 0.093*\"famili\" + 0.093*\"...\"`\r\n\r\n###...\r\n\r\n`Topic 9: -0.242*\"kill\" + 0.231*\"#\" + 0.222*\"!\" + 0.212*\"|-num_alpha-|\" + -0.208*\"obama\" + -0.203*\"declar\" + -0.203*\"disast\" + -0.173*\"|-num_units-|\" + 0.167*\"bomb\" + -0.150*\"for\"`\r\n\r\n`Topic 10: -0.463*\"!\" + -0.321*\"obama\" + -0.312*\"declar\" + -0.287*\"disast\" + -0.208*\"for\" + -0.200*\"@\" + -0.185*\"saipan\" + -0.184*\"typhoon\" + 0.180*\".\" + -0.166*\"devast\"`\r\n\r\n\r\n**Topic 1 = non-disaster and  Topic 2 = disaster???**\r\n\r\n![Topics](https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/cv_and_roc_data/topics.png)\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n\r\n###8. Improving Tokenization\r\n---\r\n\r\n**Parsing conjoined words** (common to hashtags and \"lazy\" tweeters)\r\n\r\n1. Build a large dictionary using google book n-grams\r\n2. Recursively generate word splits\r\n\r\n\r\nappear in tweets, (2) spell checking for sparsity reduction combined with introduction of a special token to indicate\r\na misspelling and (3) recognition of relevant named entities, e.g., news sources like NBC or CNN which may be\r\nparticularly relevant to disasters. Combined, the various steps I have proposed should lead to an enhanced\r\npredictive model with greater generalizability. This will be explicitly tested on a small, (of order 100) untrained, selflabeled\r\nset of tweets with high temporal and disaster type variation. The final pipeline of tweet >\r\ntokens >\r\ntopics >\r\nprediction will be encoded in an online Heroku app that will monitor Twitter via its API and search feature.\r\n\r\n\r\n---\r\n\r\n###8. Broadening the topic knowledge base\r\n---\r\n\r\n~10,000 Tweets (short) = good but not great vocabulary\r\n *Use word2vec mapping but only contains **words**\r\n\r\nPerhaps the greatest limitation of the current model is the limited vocabulary—a consequence of the relatively\r\nsmall sample size and temporal specificity. I have already proposed—and demonstrated the implementation of—\r\none way to partially remedy this by utilizing Google’s word2vec program to map unknown words onto known words\r\nby a similarity query (see full python notebook if interested). This does not capture nonword\r\nentities though (such\r\nas emoticons), thus I propose to build upon this strategy by amassing significantly more unlabeled Tweets to\r\ndirectly enhance the number of recognizable words. This will be accomplished via a Twitter API search for\r\ndisasterrelated\r\nkeywords using the same keywords employed by CrowdFlower in developing their dataset. With\r\nthis significantly augmented data set, I will form new, more robust Topics with a greatly expanded vocabulary for\r\nuse in the logistic regression. Topics encode wordword\r\nrelations in the tweets; therefore, if a topic encodes a\r\ncorrelation among the words “bombing, terrorist, suicide, explosive”, but only “bombing” is in the training set, the\r\napplicability of the other three words to a disaster event will be naturally captured by the model fitting to the Topic\r\nwith a strong weight on “bombing”.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}