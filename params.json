{
  "name": "Disaster Detection via Twitter",
  "tagline": "Predictive classification model for determining if a Tweet is discussing a disaster event (i.e., building collapse, wildfire, terrorist attack)",
  "body": "---\r\n###1. Project summary\r\n---\r\n**Goal:** Create a predictive model to classify a tweet as pertaining to a disaster event or not, *solely* based on the tweet text.\r\n\r\n**Data:** 10,876 classified tweet entries in the \"Disasters on Social Media\" data set from CrowdFlower at http://www.crowdflower.com/data-for-everyone. These were compiled by searching for tweets with disaster related keywords (i.e., hijacking, hurricane, and explosion) and then they were classified.\r\n\r\n**Machine learning tools** \r\n\r\n1. **Natural Language Toolkit (NLTK)** - For initial preprocessing and tokenization of tweets using the nltk.tokenize package.\r\n\r\n2. **GENSIM** - For transforming the high dimensional \"bag of words\" (BOW) feature space to a lower dimensional \"topic\" space via Latent Semantic Indexing or LSI.\r\n\r\n3. **Scikit-Learn** - Fitting of final Logistic Regression classification model to tweets in \"topic\" form.\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n###2. Tweet preparation\r\n---\r\n1. Convert hyphens and apostrophes from utf8 to ascii\r\n2. Remove all remaining utf8 characters\r\n3. Clean any HTML tags using HTMLParser module\r\n4. Break on hyphens\r\n5. Employ NLTK for initial tweet tokenization\r\n  * Keep handles (username) and hashtags and reduce length (e.g., looooooovvvvveeee to looovvveee)\r\n  * @ and # are separated from text\r\n6. **(New)** Split @ and # text using [token splitting tool](http://rjadrich.github.io/disaster_detection_via_twitter/index.html#8-improving-tokenization)\r\n7. **(New)** Map [top 90%](http://www.datagenetics.com/blog/october52012/index.html) of emoticons to **|-happy-|**, **|-sad-|** or **|-inert-|** tokens\r\n8. Introduce special tokens\r\n  * **|-num-|** for numbers (detect comma separation as in 1,000,000)\r\n  * **|-num_alpha-|** for mixed numerical and alphabetical (interstates, planes, trains) but not handles \r\n  * **|-num_units-|** for zero, one, ..., ten\r\n  * **|-num_tens-|** for ten, twenty, ..., ninety\r\n  * **|-num_scales-|** for hundred, thousand, ..., billion\r\n  * **|-website-|** for any hyperlinks\r\n9. Stem words using NLTK Porter stemmer (e.g., fires becomes fire)\r\n\r\n**NOTE:** stop words (like \"and\") are not removed as keeping them improves performance--perhaps by allowing for better word-word relations to be encoded in the discovered \"topics\".\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n\r\n###3. Mapping uncommon words\r\n---\r\n**Low frequency words**: occur *once* in the whole cleaned and tokenized tweet data set (also for unknown words).\r\n\r\n**High frequency words**: occur greater than *once* in the whole cleaned and tokenized tweet data set.\r\n\r\nLeverage word2vec and pre-trained Google News vectors to quantify the similarity between two words. Low frequency *stemmed* tokens are replaced by most similar high frequency *stemmed* token (see cartoon).\r\n\r\n![mapping_visual2](https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/images/mapping_procedure.png)\r\n\r\nEmploy special **|-no_w2v-|** token for word2vec unrecognized words.\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n\r\n###4. Tweet topic generation\r\n---\r\n\r\n**Steps:**\r\n\r\n1. **Bag of words (BOW)**:  vectors like [1,0,0,2,4,0,...,0] where each count specifies how many time a certain token appears in a tweet (sparse, i.e., mostly full of 0's).\r\n2. **Term frequency–inverse document frequency (TFIDF)**: rescaled BOW vectors where each word count is penalized (shrunk) in accord with how many of the documents contains the word (measure of uniqueness).\r\n3. **Latent semantic indexing (LSI)**: constructs *user specified* number of \"topics\" (linear combinations of the old TFIDF dimensions). These are constructed so so as to describe as much variance in the data as possible. \r\n\r\n**Dictionary**: tokens from *all* the tweets for get maximal word recognition. Tokens that appear only once are excluded.\r\n\r\n**Corpus**: only tweets of 100% confidence in classification to maximize reliability (some tweets with <100% appeared incorrectly labeled upon personal inspection).\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n\r\n###5. Accuracy and number of topics\r\n---\r\n\r\n**Model used**: logistic regression (well suited to high dimensional problems).\r\n\r\n![cross validation](https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/cv_and_roc_data/cross_validation_adv_parse.png)\r\n\r\n**Conclusion**: CV accuracy of ~88% near D=250. I use this dimensionality from here onward.\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n###6. Model class separability\r\n---\r\n\r\n**Receiver operating characteristic (ROC) curve:**\r\n\r\n![ROC analysis](https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/cv_and_roc_data/roc_adv_parse.png)\r\n\r\n**NOTE**: May want to tune threshold towards more false disaster predictions (better safe than sorry).\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n###7. Explore the topics\r\n---\r\n\r\n**Top 10 topics with the top ten tokens**\r\n\r\n\r\n`Topic 0: 0.403*\"?\" + 0.237*\"#\" + 0.196*\"'\" + 0.185*\"the\" + 0.184*\".\" + 0.177*\"a\" + 0.170*\"i\" + 0.168*\"@\" + 0.167*\"|-num-|\" + 0.149*\":\"`\r\n\r\n`Topic 1: -0.826*\"?\" + 0.156*\"'\" + 0.147*\"|-num-|\" + 0.145*\":\" + 0.106*\"#\" + 0.105*\"of\" + 0.098*\"famili\" + 0.098*\"in\" + 0.092*\"by\" + 0.091*\"|-website-|\"`\r\n\r\n###...\r\n\r\n`Topic 5: 0.298*\"suicid\" + 0.266*\"bomber\" + 0.210*\"bomb\" + 0.201*\"kill\" + 0.191*\"#\" + 0.177*\"mosqu\" + 0.172*\"saudi\" + 0.172*\"|-num-|\" + 0.148*\"?\" + 0.146*\"pkk\"`\r\n\r\n`Topic 6: 0.569*\"#\" + -0.198*\"bomb\" + -0.196*\"suicid\" + -0.184*\"bomber\" + -0.156*\"pkk\" + -0.152*\"turkey\" + -0.152*\"trench\" + -0.151*\"deton\" + -0.146*\"old\" + 0.140*\"|-num-|\"`\r\n\r\n\r\n**Topic 1 = non-disaster and  Topic 5 = disaster???**\r\n\r\n![Topics](https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/cv_and_roc_data/topics-adv_parse.png)\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n\r\n###8. Improving tokenization\r\n---\r\n\r\n**Parsing conjoined words** (common to hashtags)\r\n\r\nIn development since challenge [click for demo using the Brown corpus](https://github.com/rjadrich/disaster_detection_via_twitter/blob/master/token_splicer_example.ipynb) \r\n\r\n\r\n1. Corpus > word probabilities, `P(w) ~ frequency`\r\n2. Recursively generate word splits with smoothing (unrecognized words = unit frequency)\r\n3. Maximum likelihood monogram model: `log[P(w1, w2, ..., wN)] = log[P(w1)] + log[P(w2)] + ... + log[P(wN)]`\r\n\r\nFinal model will use the huge [Rovereto Twitter Corpus](http://clic.cimec.unitn.it/amac/twitter_ngram/)\r\n\r\n**Spell checking**\r\n\r\n1. Use [PyEnchant](http://pythonhosted.org/pyenchant/tutorial.html) to find most likely correction\r\n2. Introduce **|-m_spell-|** for each misspelled word\r\n3. Interface with conjoined word parser?\r\n\r\n**Named entity recognition**\r\n\r\n1. Employ Stanford Named Entity Recognition Tagger (via [NLTK](http://www.nltk.org/api/nltk.tag.html#module-nltk.tag.stanford))\r\n2. Introduce tokens for **persons**, **places**, **organizations**, etc.\r\n\r\n&nbsp;\r\n\r\n\r\n---\r\n\r\n###9. Improving topic vocabulary\r\n---\r\n\r\n**Goal**: amass significantly more unlabeled Tweets to directly enhance the number of recognizable words. \r\n\r\n**How**: Twitter API search using the same employed by CrowdFlower. \r\n\r\n**Why does this work**: If a topic encodes a correlation among the words “bombing, terrorist, suicide, explosive”, but only “bombing” is in the training set, the applicability of the other three words to a disaster event will be naturally captured by the model fitting to the Topic with a strong weight on “bombing”.\r\n\r\nTwitter Firehose access would be great!",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}