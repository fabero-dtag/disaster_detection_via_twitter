<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Disaster detection via twitter by rjadrich</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Disaster detection via twitter</h1>
      <h2 class="project-tagline">Predictive classification model for determining if a Tweet is discussing a disaster event (i.e., building collapse, wildfire, terrorist attack)</h2>
      <a href="https://github.com/rjadrich/disaster_detection_via_twitter" class="btn">View on GitHub</a>
      <a href="https://github.com/rjadrich/disaster_detection_via_twitter/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/rjadrich/disaster_detection_via_twitter/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h3>
<a id="1-project-summary" class="anchor" href="#1-project-summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>1. Project summary</h3>

<hr>

<p><strong>Goal:</strong> Create a predictive model to classify a tweet as pertaining to a disaster event or not, <em>solely</em> based on the tweet text.</p>

<p><strong>Data:</strong> 10,876 classified tweet entries in the "Disasters on Social Media" data set from CrowdFlower at <a href="http://www.crowdflower.com/data-for-everyone">http://www.crowdflower.com/data-for-everyone</a>. These were compiled by searching for tweets with disaster related keywords (i.e., hijacking, hurricane, and explosion) and then they were classified.</p>

<p><strong>Machine learning tools</strong> </p>

<ol>
<li><p><strong>Natural Language Toolkit (NLTK)</strong> - For initial preprocessing and tokenization of tweets using the nltk.tokenize package.</p></li>
<li><p><strong>GENSIM</strong> - For seamless transformation from a high dimensional "bag of words" (BOW) feature space to a lower dimensional "topic" space via Latent Semantic Indexing or LSI.</p></li>
<li><p><strong>Scikit-Learn</strong> - Fitting of final Logistic Regression classification model to "topics" represented tweets.</p></li>
</ol>

<h3>
<a id="2-clean-and-tokenize-all-the-tweets" class="anchor" href="#2-clean-and-tokenize-all-the-tweets" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2. Clean and tokenize all the tweets</h3>

<hr>

<ol>
<li>Convert hyphens and apostrophes from utf8 to ascii</li>
<li>Remove all remaining utf8 characters</li>
<li>Clean any HTML tags using HTMLParser module</li>
<li>Break on hyphens</li>
<li>Employ NLTK for initial tweet tokenization

<ul>
<li>Keep handles (username) and hashtags and reduce length (e.g., looooooovvvvveeee to looovvveee)</li>
</ul>
</li>
<li>Introduce special tokens

<ul>
<li>
<strong>|-num-|</strong> for numbers (detect comma separation as in 1,000,000)</li>
<li>
<strong>|-num_alpha-|</strong> for mixed numerical and alphabetical (interstates, planes, trains) but not handles </li>
<li>
<strong>|-num_units-|</strong> for zero, one, ..., ten</li>
<li>
<strong>|-num_tens-|</strong> for ten, twenty, ..., ninety</li>
<li>
<strong>|-num_scales-|</strong> for hundred, thousand, ..., billion</li>
<li>
<strong>|-website-|</strong> for any hyperlinks</li>
</ul>
</li>
<li>Simplify common face emoticons down to just eyes and mouth (nose does not really convey emotion) and normalize (eyes first mouth second)

<ul>
<li>Most common eyes : ; = 8</li>
<li>Most common mouths ( ) [ ] d p { } / @ |</li>
</ul>
</li>
<li>Stem words using NLTK Porter stemmer (e.g., fires becomes fire)</li>
</ol>

<p><strong>NOTE:</strong> stop words (like "and") are not removed as keeping them improves performance--perhaps by allowing for better word-word relations to be encoded in the discovered "topics".</p>

<h3>
<a id="3-mapping-low-frequency-words-onto-high-frequency-analogs" class="anchor" href="#3-mapping-low-frequency-words-onto-high-frequency-analogs" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3. Mapping low frequency words onto high frequency analogs</h3>

<hr>

<p><strong>Low frequency words</strong>: occur <em>once</em> in the whole cleaned and tokenized tweet data set (also for unknown words).</p>

<p><strong>High frequency words</strong>: occur greater than <em>once</em> in the whole cleaned and tokenized tweet data set.</p>

<p>Employ pre-trained <strong>word2vec</strong> vectors from the Google News data set to quantify the similarity between two words. Low frequency <em>stemmed</em> tokens are replaced by most similar high frequency <em>stemmed</em> token (see cartoon).</p>

<p><img src="https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/images/mapping_procedure.png" alt="mapping_visual2"></p>

<h3>
<a id="4-converting-tweets-into-features-for-modeling" class="anchor" href="#4-converting-tweets-into-features-for-modeling" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>4. Converting tweets into features for modeling</h3>

<hr>

<p><strong>Some useful definitions:</strong></p>

<ol>
<li>
<strong>Bag of words (BOW)</strong>:  tweet vectors like [1,0,0,2,4,0,...,0] where each count specifies how many time a certain token appears in a tweet (sparse, i.e., mostly full of 0's). Please see <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">https://en.wikipedia.org/wiki/Bag-of-words_model</a> for more details.</li>
<li>
<strong>Term frequencyâ€“inverse document frequency (TFIDF)</strong>: rescaled BOW vectors where each word count is penalized (shrunk) in accord with how many of the documents contains the word (measure of uniqueness). Please see <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">https://en.wikipedia.org/wiki/Tf%E2%80%93idf</a> for more details.</li>
<li>
<strong>Latent semantic indexing (LSI)</strong>: constructs user specified number of "Topics" (linear combinations of the old TFIDF dimensions). These are constructed so so as to describe as much variance in the data as possible. Please see for <a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis">https://en.wikipedia.org/wiki/Latent_semantic_analysis</a> more details.</li>
</ol>

<p><strong>Dictionary</strong>: uses all the tweets to get maximal word recognition. Tokens that appear only once are excluded.</p>

<p><strong>Corpus</strong>: only uses tweets of 100% confidence in classification to maximize reliability (some of the tweets with less than 100% appeared incorrectly labeled upon personal inspection).</p>

<h3>
<a id="5-decide-on-a-model-dimensionality-and-check-accuracy" class="anchor" href="#5-decide-on-a-model-dimensionality-and-check-accuracy" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>5. Decide on a model dimensionality and check accuracy</h3>

<hr>

<p><strong>Model used</strong>: logistic regression (see: <a href="https://en.wikipedia.org/wiki/Logistic_regression">https://en.wikipedia.org/wiki/Logistic_regression</a>).</p>

<p><strong>Why</strong>: well suited to high dimensional problems.</p>

<p><img src="https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/cv_and_roc_data/cross_validation.png" alt="cross validation"></p>

<p><strong>Conclusion</strong>: Overall, D=250 seems good and is the dimensionality employed from here onward.</p>

<h3>
<a id="7-make-and-test-a-model-with-desired-dimensionality" class="anchor" href="#7-make-and-test-a-model-with-desired-dimensionality" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>7. Make and test a model with desired dimensionality</h3>

<hr>

<ol>
<li>Create a k-fold receiver operating characteristic (ROC) curve (see: <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">https://en.wikipedia.org/wiki/Receiver_operating_characteristic</a> for more details).

<ul>
<li>This checks how well the model "separates" the two classes by plotting the "true positive rate" vs the "false positive rate" while moving the probability cutoff for classifying into one of the two categories (the default for classification is 50%).</li>
</ul>
</li>
</ol>

<p><img src="https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/cv_and_roc_data/roc.png" alt="ROC analysis"></p>

<p>The ROC analysis suggests the model does a good job at separating out the classes. </p>

<h3>
<a id="8-check-out-the-topics" class="anchor" href="#8-check-out-the-topics" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>8. Check out the "topics"</h3>

<hr>

<p>Top 10 topics with the top ten tokens they are composed of</p>

<p><code>Topic 0: 0.426*"?" + 0.234*"#" + 0.205*"@" + 0.196*"|-no_w2v-|" + 0.188*"'" + 0.185*"." + 0.183*"the" + 0.160*"|-num-|" + 0.158*"i" + 0.156*"a"</code></p>

<p><code>Topic 1: -0.808*"?" + 0.160*"|-num-|" + 0.159*"'" + 0.148*":" + 0.127*"#" + 0.110*"of" + 0.107*"in" + 0.096*"|-website-|" + 0.093*"famili" + 0.093*"..."</code></p>

<h3>
<a id="" class="anchor" href="#" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>...</h3>

<p><code>Topic 9: -0.242*"kill" + 0.231*"#" + 0.222*"!" + 0.212*"|-num_alpha-|" + -0.208*"obama" + -0.203*"declar" + -0.203*"disast" + -0.173*"|-num_units-|" + 0.167*"bomb" + -0.150*"for"</code></p>

<p><code>Topic 10: -0.463*"!" + -0.321*"obama" + -0.312*"declar" + -0.287*"disast" + -0.208*"for" + -0.200*"@" + -0.185*"saipan" + -0.184*"typhoon" + 0.180*"." + -0.166*"devast"</code></p>

<p>Topic 1 = non-disaster?  |  Topic 2 = disaster?</p>

<p>Lets see:</p>

<p><img src="https://raw.githubusercontent.com/rjadrich/disaster_detection_via_twitter/master/data/cv_and_roc_data/topics.png" alt="Topics"></p>

<h3>
<a id="8-proposed-work" class="anchor" href="#8-proposed-work" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>8. Proposed work</h3>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/rjadrich/disaster_detection_via_twitter">Disaster detection via twitter</a> is maintained by <a href="https://github.com/rjadrich">rjadrich</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
